{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple CSVC Classifier with subsequence string kernel\n",
    "\n",
    "The shogun toolbox was used for creating a CSVC, changing the feature lengths and the values of C.\n",
    "\n",
    "One limitation of the kernel is that the strings must be longer than the subsequence length used, as recursion is not possible otherwise, which makes it necessary to filter the news according to their length, along with their class.\n",
    "\n",
    "The base code for doung all this is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import shogun as sh\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('news.txt') as f:\n",
    "    news = f.readlines()\n",
    "    \n",
    "with open ('labels.txt') as g:\n",
    "    labels = g.readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "\n",
    "featl = 5\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i] == ('us' or labels[i] == 'world') and len(news[i])>featl:\n",
    "        Y.append(1)\n",
    "        X.append(news[i])\n",
    "    elif(labels[i] == ('sport' or labels[i] == 'entertainment') and len(news[i])>featl:\n",
    "        Y.append(-1)\n",
    "        X.append(news[i])\n",
    "        \n",
    "y = np.array(Y)\n",
    "x = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)\n",
    "\n",
    "features = sh.StringCharFeatures(list(X_train[:10000], sh.RAWBYTE)\n",
    "features_test = sh.StringCharFeatures(list(X_test[:10000], sh.RAWBYTE)\n",
    "\n",
    "labeling = sh.BinaryLabels(y_train[:10000].astype(int))\n",
    "labels_test = sh.BinaryLabels(y_test[:10000].astype(int))\n",
    "stk = sh.SubsequenceStringKernel(features, features, featl, 0.5)\n",
    "\n",
    "svm = sh.LibSVM(10000, stk, labeling)\n",
    "svm.train()\n",
    "labels_predict = svm.apply_binary(features_test)\n",
    "evals = sh.AccuracyMeasure()\n",
    "accuracy = evals.evaluate(labels_predict, labels_test)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "Some problems related to the use of this kernel have to do with the ammount of time it takes to train, which may be a result of having too many support vectors, as there is currently no $ \\nu$SVC implementation in this toolbox that I know of.\n",
    "\n",
    "For this reason, classifiers were found using only 500 training and testing samples in order to have a reasonable guess of the best parameters and subsequently create a better classifier using 10000 training and testing samples.\n",
    "\n",
    "The results are obtained as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|C|Accuracy fl(5)|Accuracy fl(25)|\n",
    "    |------|--------|--------|\n",
    "    | 1 |   0.748  |      0.664     |\n",
    "    | 10 |   0.828  |      0.78     |\n",
    "    | 100 |   0.792  |      0.828     |\n",
    "    | 1000 |   0.808  |      0.796     |\n",
    "    | 10000 |   0.84  |      0.85     |\n",
    "    | 100000 |   0.822  |      0.8     |\n",
    "    | 1000000 |   0.842  |      0.782     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracies in the testing dataset with feature lengths of 5 and 25 are obtained with a value of 10000 for C, and the best feature length is 5, which is the reason why this paramenters are chosen to create a better classifier for 10000 training samples and this model is evaluated in 10000 more samples. A higher number of training samples is not chosen because the training time doesn't scale linearly with the number of samples, so a better accuracy estimate is chosen instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration leads to an accuracy of 0.8452 and the error can be found using Chernoff's absolute error bounds as:\n",
    "\n",
    "$$ e=\\sqrt{\\frac{1}{2*400}\\frac{1}{\\ln(\\frac{1}{0.025})}}\\approx 0.3\\% $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
